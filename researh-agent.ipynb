{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\deepseek-r1-experiment-notebooks\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Dict\n",
    "from smolagents import CodeAgent, tool, LiteLLMModel , GradioUI,OpenAIServerModel\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def scrape_real_estate_agents(state: str, city_name: str, num_pages: Optional[int] = 2) -> Dict[str, any]:\n",
    "    \"\"\"Scrapes realtor.com for real estate agent information in specified city and state\n",
    "    \n",
    "    Args:\n",
    "        state: State abbreviation (e.g., 'CA', 'NY')\n",
    "        city_name: City name with hyphens instead of spaces (e.g., 'buffalo')\n",
    "        num_pages: Number of pages to scrape (default: 2)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize results\n",
    "        agent_names = []         # Names\n",
    "        agent_phones = []        # Phone numbers\n",
    "        agent_offices = []       # Office names\n",
    "        pages_scraped = 0\n",
    "        \n",
    "        # Set up headers\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "            \"Connection\": \"keep-alive\"\n",
    "        }\n",
    "\n",
    "        # Process pages\n",
    "        for page in range(1, num_pages + 1):\n",
    "            # Construct URL\n",
    "            if page == 1:\n",
    "                url = f'https://www.realtor.com/realestateagents/{city_name}_{state}/'\n",
    "            else:\n",
    "                url = f'https://www.realtor.com/realestateagents/{city_name}_{state}/pg-{page}'\n",
    "            \n",
    "            print(f\"Scraping page {page}...\")\n",
    "            \n",
    "            # Get page content\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code != 200:\n",
    "                return {\"error\": f\"Failed to access page {page}: Status code {response.status_code}\"}\n",
    "\n",
    "            soup = BeautifulSoup(response.text, features=\"html.parser\")\n",
    "            \n",
    "            # Find all agent cards\n",
    "            agent_cards = soup.find_all('div', class_='agent-list-card')\n",
    "            \n",
    "            for card in agent_cards:\n",
    "                # Find name\n",
    "                name_elem = card.find('div', class_='agent-name')\n",
    "                if name_elem:\n",
    "                    name = name_elem.text.strip()\n",
    "                    if name and name not in agent_names:\n",
    "                        agent_names.append(name)\n",
    "                        print(f\"Found agent: {name}\")\n",
    "\n",
    "                # Find phone\n",
    "                phone_elem = card.find('a', {'data-testid': 'agent-phone'}) or \\\n",
    "                            card.find(class_='btn-contact-me-call') or \\\n",
    "                            card.find('a', href=lambda x: x and x.startswith('tel:'))\n",
    "                \n",
    "                if phone_elem:\n",
    "                    phone = phone_elem.get('href', '').replace('tel:', '').strip()\n",
    "                    if phone:\n",
    "                        agent_phones.append(phone)\n",
    "                        print(f\"Found phone: {phone}\")\n",
    "\n",
    "                # Get office/company name\n",
    "                office_elem = card.find('div', class_='agent-group') or \\\n",
    "                            card.find('div', class_='text-semibold')\n",
    "                if office_elem:\n",
    "                    office = office_elem.text.strip()\n",
    "                    agent_offices.append(office)\n",
    "                    print(f\"Found office: {office}\")\n",
    "                else:\n",
    "                    agent_offices.append(\"\")\n",
    "            \n",
    "            pages_scraped += 1\n",
    "            time.sleep(2)  # Rate limiting\n",
    "\n",
    "        if not agent_names:\n",
    "            return {\"error\": \"No agents found. The website structure might have changed or no results for this location.\"}\n",
    "\n",
    "        # Return structured data\n",
    "        return {\n",
    "            \"names\": agent_names,\n",
    "            \"phones\": agent_phones,\n",
    "            \"offices\": agent_offices,\n",
    "            \"total_agents\": len(agent_names),\n",
    "            \"pages_scraped\": pages_scraped,\n",
    "            \"city\": city_name,\n",
    "            \"state\": state\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Scraping error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def export_to_csv(scraped_data: Dict[str, any], output_filename: Optional[str] = None) -> str:\n",
    "    \"\"\"Exports scraped real estate agent data to a CSV file\n",
    "    \n",
    "    Args:\n",
    "        scraped_data: Dictionary containing the results of the scraping\n",
    "        output_filename: Optional filename for the CSV file (default: cityname.csv)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if \"error\" in scraped_data:\n",
    "            return f\"Error: {scraped_data['error']}\"\n",
    "            \n",
    "        if not output_filename:\n",
    "            output_filename = f\"{scraped_data['city'].replace('-', '')}.csv\"\n",
    "            \n",
    "        # Ensure all lists are of equal length\n",
    "        max_length = max(len(scraped_data['names']), len(scraped_data['phones']), len(scraped_data['offices']))\n",
    "        \n",
    "        # Pad shorter lists with empty strings\n",
    "        scraped_data['names'].extend([\"\"] * (max_length - len(scraped_data['names'])))\n",
    "        scraped_data['phones'].extend([\"\"] * (max_length - len(scraped_data['phones'])))\n",
    "        scraped_data['offices'].extend([\"\"] * (max_length - len(scraped_data['offices'])))\n",
    "        \n",
    "        # Create DataFrame with just names, phones, and offices\n",
    "        df = pd.DataFrame({\n",
    "            'Names': scraped_data['names'],\n",
    "            'Phone': scraped_data['phones'],\n",
    "            'Office': scraped_data['offices']\n",
    "        })\n",
    "        \n",
    "        df.to_csv(output_filename, index=False, encoding='utf-8')\n",
    "        return f\"Data saved to {output_filename}. Total entries: {len(df)}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error saving CSV: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_model =  OpenAIServerModel(\n",
    "            model_id=\"deepseek-r1:7b\",\n",
    "            api_base=\"http://localhost:11434/v1\",\n",
    "            api_key=\"ollama\"\n",
    "        )\n",
    "\n",
    "    # Create agent with tools\n",
    "agent = CodeAgent(\n",
    "    tools=[scrape_real_estate_agents, export_to_csv],\n",
    "    model=deepseek_model,\n",
    "    additional_authorized_imports=[\"pandas\", \"bs4\", \"time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Thought: Let's scrape realtor data</span>                                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Code:</span>                                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">```python</span>                                                                                                       <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\"># Scrape realtor data</span>                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">data = scrape_realtor(state=\"NY\", city_name=\"buffalo\", num_pages=2)</span>                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\"># Save to CSV</span>                                                                                                   <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">if \"error\" not in data:</span>                                                                                         <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    result = save_to_csv(data)</span>                                                                                  <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    print(result)</span>                                                                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">else:</span>                                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    print(f\"Error: {data['error']}\")</span>                                                                            <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">```</span>                                                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIServerModel - deepseek-r1:7b ────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mThought: Let's scrape realtor data\u001b[0m                                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mCode:\u001b[0m                                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m```python\u001b[0m                                                                                                       \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m# Scrape realtor data\u001b[0m                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mdata = scrape_realtor(state=\"NY\", city_name=\"buffalo\", num_pages=2)\u001b[0m                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m# Save to CSV\u001b[0m                                                                                                   \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mif \"error\" not in data:\u001b[0m                                                                                         \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    result = save_to_csv(data)\u001b[0m                                                                                  \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    print(result)\u001b[0m                                                                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1melse:\u001b[0m                                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    print(f\"Error: {data['error']}\")\u001b[0m                                                                            \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m```\u001b[0m                                                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIServerModel - deepseek-r1:7b \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = agent.run(\"\"\"\n",
    "Thought: Let's scrape realtor data\n",
    "Code:\n",
    "```python\n",
    "# Scrape realtor data\n",
    "data = scrape_realtor(state=\"NY\", city_name=\"buffalo\", num_pages=2)\n",
    "\n",
    "# Save to CSV\n",
    "if \"error\" not in data:\n",
    "    result = save_to_csv(data)\n",
    "    print(result)\n",
    "else:\n",
    "    print(f\"Error: {data['error']}\")\n",
    "```\n",
    "\"\"\")\n",
    "    \n",
    "print(result)\n",
    "GradioUI(agent).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
