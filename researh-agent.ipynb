{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict\n",
    "from smolagents import CodeAgent, tool, LiteLLMModel , GradioUI,OpenAIServerModel\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def scrape_realtor(state: str, city_name: str, num_pages: Optional[int] = 2) -> Dict[str, any]:\n",
    "    \"\"\"Scrapes realtor.com for agent information in specified city and state\n",
    "    \n",
    "    Args:\n",
    "        state: State abbreviation (e.g., 'CA', 'NY')\n",
    "        city_name: City name with hyphens instead of spaces (e.g., 'buffalo')\n",
    "        num_pages: Number of pages to scrape (default: 2)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize results\n",
    "        results = []         # Names\n",
    "        phone_results = []   # Phone numbers\n",
    "        office_results = []  # Office names\n",
    "        pages_scraped = 0\n",
    "        \n",
    "        # Set up headers\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "            \"Connection\": \"keep-alive\"\n",
    "        }\n",
    "\n",
    "        # Process pages\n",
    "        for page in range(1, num_pages + 1):\n",
    "            # Construct URL\n",
    "            if page == 1:\n",
    "                url = f'https://www.realtor.com/realestateagents/{city_name}_{state}/'\n",
    "            else:\n",
    "                url = f'https://www.realtor.com/realestateagents/{city_name}_{state}/pg-{page}'\n",
    "            \n",
    "            print(f\"Scraping page {page}...\")\n",
    "            \n",
    "            # Get page content\n",
    "            r = requests.get(url, headers=headers)\n",
    "            if r.status_code != 200:\n",
    "                return {\"error\": f\"Failed to access page {page}: Status code {r.status_code}\"}\n",
    "\n",
    "            soup = BeautifulSoup(r.text, features=\"html.parser\")\n",
    "            \n",
    "            # Find all agent cards\n",
    "            agent_cards = soup.find_all('div', class_='agent-list-card')\n",
    "            \n",
    "            for card in agent_cards:\n",
    "                # Find name\n",
    "                name_elem = card.find('div', class_='agent-name')\n",
    "                if name_elem:\n",
    "                    name = name_elem.text.strip()\n",
    "                    if name and name not in results:\n",
    "                        results.append(name)\n",
    "                        print(f\"Found agent: {name}\")\n",
    "\n",
    "                # Find phone\n",
    "                phone_elem = card.find('a', {'data-testid': 'agent-phone'}) or \\\n",
    "                            card.find(class_='btn-contact-me-call') or \\\n",
    "                            card.find('a', href=lambda x: x and x.startswith('tel:'))\n",
    "                \n",
    "                if phone_elem:\n",
    "                    phone = phone_elem.get('href', '').replace('tel:', '').strip()\n",
    "                    if phone:\n",
    "                        phone_results.append(phone)\n",
    "                        print(f\"Found phone: {phone}\")\n",
    "\n",
    "                # Get office/company name\n",
    "                office_elem = card.find('div', class_='agent-group') or \\\n",
    "                            card.find('div', class_='text-semibold')\n",
    "                if office_elem:\n",
    "                    office = office_elem.text.strip()\n",
    "                    office_results.append(office)\n",
    "                    print(f\"Found office: {office}\")\n",
    "                else:\n",
    "                    office_results.append(\"\")\n",
    "            \n",
    "            pages_scraped += 1\n",
    "            time.sleep(2)  # Rate limiting\n",
    "\n",
    "        if not results:\n",
    "            return {\"error\": \"No agents found. The website structure might have changed or no results for this location.\"}\n",
    "\n",
    "        # Return structured data\n",
    "        return {\n",
    "            \"names\": results,\n",
    "            \"phones\": phone_results,\n",
    "            \"offices\": office_results,\n",
    "            \"total_agents\": len(results),\n",
    "            \"pages_scraped\": pages_scraped,\n",
    "            \"city\": city_name,\n",
    "            \"state\": state\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Scraping error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def save_to_csv(data: Dict[str, any], filename: Optional[str] = None) -> str:\n",
    "    \"\"\"Saves scraped realtor data to CSV file\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary containing scraping results\n",
    "        filename: Optional filename (default: cityname.csv)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if \"error\" in data:\n",
    "            return f\"Error: {data['error']}\"\n",
    "            \n",
    "        if not filename:\n",
    "            filename = f\"{data['city'].replace('-', '')}.csv\"\n",
    "            \n",
    "        # Ensure all lists are of equal length\n",
    "        max_length = max(len(data['names']), len(data['phones']), len(data['offices']))\n",
    "        \n",
    "        # Pad shorter lists with empty strings\n",
    "        data['names'].extend([\"\"] * (max_length - len(data['names'])))\n",
    "        data['phones'].extend([\"\"] * (max_length - len(data['phones'])))\n",
    "        data['offices'].extend([\"\"] * (max_length - len(data['offices'])))\n",
    "        \n",
    "        # Create DataFrame with just names, phones, and offices\n",
    "        df = pd.DataFrame({\n",
    "            'Names': data['names'],\n",
    "            'Phone': data['phones'],\n",
    "            'Office': data['offices']\n",
    "        })\n",
    "        \n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        return f\"Data saved to {filename}. Total entries: {len(df)}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error saving CSV: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_model =  OpenAIServerModel(\n",
    "            model_id=\"deepseek-r1:7b\",\n",
    "            api_base=\"http://localhost:11434/v1\",\n",
    "            api_key=\"ollama\"\n",
    "        )\n",
    "\n",
    "    # Create agent with tools\n",
    "agent = CodeAgent(\n",
    "    tools=[scrape_realtor, save_to_csv],\n",
    "    model=deepseek_model,\n",
    "    additional_authorized_imports=[\"pandas\", \"bs4\", \"time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Thought: Let's scrape realtor data</span>                                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Code:</span>                                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">```python</span>                                                                                                       <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\"># Scrape realtor data</span>                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">data = scrape_realtor(state=\"NY\", city_name=\"buffalo\", num_pages=2)</span>                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\"># Save to CSV</span>                                                                                                   <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">if \"error\" not in data:</span>                                                                                         <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    result = save_to_csv(data)</span>                                                                                  <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    print(result)</span>                                                                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">else:</span>                                                                                                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    print(f\"Error: {data['error']}\")</span>                                                                            <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">```</span>                                                                                                             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIServerModel - deepseek-r1:7b ────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mThought: Let's scrape realtor data\u001b[0m                                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mCode:\u001b[0m                                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m```python\u001b[0m                                                                                                       \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m# Scrape realtor data\u001b[0m                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mdata = scrape_realtor(state=\"NY\", city_name=\"buffalo\", num_pages=2)\u001b[0m                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m# Save to CSV\u001b[0m                                                                                                   \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mif \"error\" not in data:\u001b[0m                                                                                         \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    result = save_to_csv(data)\u001b[0m                                                                                  \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    print(result)\u001b[0m                                                                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1melse:\u001b[0m                                                                                                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    print(f\"Error: {data['error']}\")\u001b[0m                                                                            \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m```\u001b[0m                                                                                                             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIServerModel - deepseek-r1:7b \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in code parsing:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Your code snippet is invalid, because the regex pattern ```(?:py|python)?\\n(.*?)\\n``` was not found in it.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Here is your code snippet:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">&lt;think&gt;</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Okay, so I've been given this Python code that's supposed to scrape realtor data. Let me try to figure out what it </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">does and what's going on here.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">First part of the code is a call to a function called scrape_realtor. It has three parameters: state set to </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"NY\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">city_name as </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"buffalo\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, and num_pages set to </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">. Then, if there's no key </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'error'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> in the data dictionary returned by </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">this function, it proceeds to save the data to a CSV file using another function called save_to_csv. If an error is</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">present, it catches that and prints the error message.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Hmm, I'm guessing that the scrape_realtor function makes some HTTP requests and parses HTML content from realtor </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">websites to extract data about properties in Buffalo, NY. Since it's limited to </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> pages (</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">num_pages</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">=</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">), maybe each </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">page has multiple listings.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Wait, but how does the data structure look? If there's an </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'error'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> key, perhaps that means the scraping failed for </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">some reason—like a network error or a bad HTML response. So before saving, the code checks if the </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'error'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> key </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">exists to handle it gracefully.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The save_to_csv function then writes this scraped data into a CSV file. I'm not exactly sure what keys are in the </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">data dictionary from scrape_realtor, but likely each dictionary represents a realtor listing with attributes like </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">price, number of beds, baths, square footage, etc., and maybe also URL or other info.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">I wonder if I should validate this code. Maybe think about possible issues—like why would there be an error? Is the</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">website down, or are there </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">404</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> pages for certain states or cities? Also, is num_pages correctly handling multiple </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">page scraper?</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Another thought: since the data might include URLs, and sometimes realtor sites require logging in to scrape data. </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">If that's the case, then this code wouldn't work because it can't access those listings without user </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">authentication.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Also, maybe there are pagination issues. Since only </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> pages, perhaps some properties are on page </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> or </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, but if it </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">doesn't handle loading more pages due to JavaScript or APIs requiring interaction, it might not get all data.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">I should also check how the save_to_csv function is implemented. If it's using pandas, that would help structure </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">the CSV properly with headers and rows. But without seeing its code, I can only assume.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Potential steps to improve:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">. Error handling: Maybe add more detailed error messages or logging.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">. Check if all pages are being parsed correctly—maybe some pages return empty data beyond a certain point.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">3</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">. Add authentication if the site requires user input for scraping.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">4</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">. Test the code with different parameters and see how it handles various states, cities, and page numbers.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">I think one thing might be bothering me is assuming that scrape_realtor's response doesn't have an </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'error'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> key </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">except when something goes wrong. But perhaps in some scenarios, like if a property listing has errors on the </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">website (e.g., unsupported elements), it could return an error even without exceptions? Not sure.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Also, I should consider that sometimes scraping might change over time as HTML structures evolve. So if </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">scrape_realtor is making assumptions about the page structure, future changes could break the scraper unless it's </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">properly updated.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Another point: The response from the server might have different content types or might require certain headers to </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">be sent by the scraper client—like adding user-agent information for realtor sites which may block scrapers </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">otherwise. Not sure if this code includes that, as a basic scraper.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">So in summary, my thought process is:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">- Acknowledge that the code's intent is to scrape realtor data from Buffalo, NY.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">- Question why there is an </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'error'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> key—maybe it's for failed requests elsewhere besides what might be expected.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">- Consider possible issues like authentication needed, incorrect pagination handling, and structural HTML problems.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">- Suggest adding more robust error handling, logging, and considerations about scraping ethics or遵守.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">&lt;/think&gt;</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The code provided is designed to scrape realtor data from Buffalo, NY, limited to two pages. Here's a concise </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">explanation of its functionality and suggested improvements:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">### Explanation</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">. **Scraping Process**:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">   - Calls `scrape_realtor` with state </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"NY\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, city </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\"buffalo\"</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">, and </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> pages.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">   - Expects the response (data) without errors; if an error exists, it exits.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">. **Data Handling**:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">   - The data likely contains various property details such as price, beds, baths, etc., structured in a dictionary</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">per listing.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">   - `save_to_csv` writes this data into a CSV file for further analysis or reporting.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">3</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">. **Potential Issues**:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">   - Assumes the response is an empty </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'error'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> key upon failure, but realtor sites might have different error </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">indicators.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">   - Does not handle authentication issues common on some websites that require login for scraping.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">   - Might fail if HTML structure changes between requests due to updates by realtor listings.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">   - Could encounter pagination limits without proper handling of JavaScript or APIs.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">### Suggestions for Improvement</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">- **Error Handling**: Expand beyond checking the </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">'error'</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> key. Incorporate detailed exception logging.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">- **Authentication**: Implement user agent headers and authentication methods required by the website.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">- **Testing**: Test with various states, cities, and page numbers to ensure robustness.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">- **Logging**: Add comprehensive logs for trouble-shooting issues efficiently.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The code seems basic but offers a foundation that requires enhancement for reliability and effectiveness.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Make sure to include code with the correct pattern, for instance:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Thoughts: Your thoughts</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Code:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">```py</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"># Your python code here</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">```&lt;end_code&gt;</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Make sure to provide correct code blobs.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in code parsing:\u001b[0m\n",
       "\u001b[1;31mYour code snippet is invalid, because the regex pattern ```\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m?:py|python\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m?\\\u001b[0m\u001b[1;31mn\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m.*?\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m\\n``` was not found in it.\u001b[0m\n",
       "\u001b[1;31mHere is your code snippet:\u001b[0m\n",
       "\u001b[1;31m<\u001b[0m\u001b[1;31mthink\u001b[0m\u001b[1;31m>\u001b[0m\n",
       "\u001b[1;31mOkay, so I've been given this Python code that's supposed to scrape realtor data. Let me try to figure out what it \u001b[0m\n",
       "\u001b[1;31mdoes and what's going on here.\u001b[0m\n",
       "\n",
       "\u001b[1;31mFirst part of the code is a call to a function called scrape_realtor. It has three parameters: state set to \u001b[0m\u001b[1;31m\"NY\"\u001b[0m\u001b[1;31m, \u001b[0m\n",
       "\u001b[1;31mcity_name as \u001b[0m\u001b[1;31m\"buffalo\"\u001b[0m\u001b[1;31m, and num_pages set to \u001b[0m\u001b[1;31m2\u001b[0m\u001b[1;31m. Then, if there's no key \u001b[0m\u001b[1;31m'error'\u001b[0m\u001b[1;31m in the data dictionary returned by \u001b[0m\n",
       "\u001b[1;31mthis function, it proceeds to save the data to a CSV file using another function called save_to_csv. If an error is\u001b[0m\n",
       "\u001b[1;31mpresent, it catches that and prints the error message.\u001b[0m\n",
       "\n",
       "\u001b[1;31mHmm, I'm guessing that the scrape_realtor function makes some HTTP requests and parses HTML content from realtor \u001b[0m\n",
       "\u001b[1;31mwebsites to extract data about properties in Buffalo, NY. Since it's limited to \u001b[0m\u001b[1;31m2\u001b[0m\u001b[1;31m pages \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mnum_pages\u001b[0m\u001b[1;31m=\u001b[0m\u001b[1;31m2\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m, maybe each \u001b[0m\n",
       "\u001b[1;31mpage has multiple listings.\u001b[0m\n",
       "\n",
       "\u001b[1;31mWait, but how does the data structure look? If there's an \u001b[0m\u001b[1;31m'error'\u001b[0m\u001b[1;31m key, perhaps that means the scraping failed for \u001b[0m\n",
       "\u001b[1;31msome reason—like a network error or a bad HTML response. So before saving, the code checks if the \u001b[0m\u001b[1;31m'error'\u001b[0m\u001b[1;31m key \u001b[0m\n",
       "\u001b[1;31mexists to handle it gracefully.\u001b[0m\n",
       "\n",
       "\u001b[1;31mThe save_to_csv function then writes this scraped data into a CSV file. I'm not exactly sure what keys are in the \u001b[0m\n",
       "\u001b[1;31mdata dictionary from scrape_realtor, but likely each dictionary represents a realtor listing with attributes like \u001b[0m\n",
       "\u001b[1;31mprice, number of beds, baths, square footage, etc., and maybe also URL or other info.\u001b[0m\n",
       "\n",
       "\u001b[1;31mI wonder if I should validate this code. Maybe think about possible issues—like why would there be an error? Is the\u001b[0m\n",
       "\u001b[1;31mwebsite down, or are there \u001b[0m\u001b[1;31m404\u001b[0m\u001b[1;31m pages for certain states or cities? Also, is num_pages correctly handling multiple \u001b[0m\n",
       "\u001b[1;31mpage scraper?\u001b[0m\n",
       "\n",
       "\u001b[1;31mAnother thought: since the data might include URLs, and sometimes realtor sites require logging in to scrape data. \u001b[0m\n",
       "\u001b[1;31mIf that's the case, then this code wouldn't work because it can't access those listings without user \u001b[0m\n",
       "\u001b[1;31mauthentication.\u001b[0m\n",
       "\n",
       "\u001b[1;31mAlso, maybe there are pagination issues. Since only \u001b[0m\u001b[1;31m2\u001b[0m\u001b[1;31m pages, perhaps some properties are on page \u001b[0m\u001b[1;31m1\u001b[0m\u001b[1;31m or \u001b[0m\u001b[1;31m2\u001b[0m\u001b[1;31m, but if it \u001b[0m\n",
       "\u001b[1;31mdoesn't handle loading more pages due to JavaScript or APIs requiring interaction, it might not get all data.\u001b[0m\n",
       "\n",
       "\u001b[1;31mI should also check how the save_to_csv function is implemented. If it's using pandas, that would help structure \u001b[0m\n",
       "\u001b[1;31mthe CSV properly with headers and rows. But without seeing its code, I can only assume.\u001b[0m\n",
       "\n",
       "\u001b[1;31mPotential steps to improve:\u001b[0m\n",
       "\u001b[1;31m1\u001b[0m\u001b[1;31m. Error handling: Maybe add more detailed error messages or logging.\u001b[0m\n",
       "\u001b[1;31m2\u001b[0m\u001b[1;31m. Check if all pages are being parsed correctly—maybe some pages return empty data beyond a certain point.\u001b[0m\n",
       "\u001b[1;31m3\u001b[0m\u001b[1;31m. Add authentication if the site requires user input for scraping.\u001b[0m\n",
       "\u001b[1;31m4\u001b[0m\u001b[1;31m. Test the code with different parameters and see how it handles various states, cities, and page numbers.\u001b[0m\n",
       "\n",
       "\u001b[1;31mI think one thing might be bothering me is assuming that scrape_realtor's response doesn't have an \u001b[0m\u001b[1;31m'error'\u001b[0m\u001b[1;31m key \u001b[0m\n",
       "\u001b[1;31mexcept when something goes wrong. But perhaps in some scenarios, like if a property listing has errors on the \u001b[0m\n",
       "\u001b[1;31mwebsite \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31me.g., unsupported elements\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m, it could return an error even without exceptions? Not sure.\u001b[0m\n",
       "\n",
       "\u001b[1;31mAlso, I should consider that sometimes scraping might change over time as HTML structures evolve. So if \u001b[0m\n",
       "\u001b[1;31mscrape_realtor is making assumptions about the page structure, future changes could break the scraper unless it's \u001b[0m\n",
       "\u001b[1;31mproperly updated.\u001b[0m\n",
       "\n",
       "\u001b[1;31mAnother point: The response from the server might have different content types or might require certain headers to \u001b[0m\n",
       "\u001b[1;31mbe sent by the scraper client—like adding user-agent information for realtor sites which may block scrapers \u001b[0m\n",
       "\u001b[1;31motherwise. Not sure if this code includes that, as a basic scraper.\u001b[0m\n",
       "\n",
       "\u001b[1;31mSo in summary, my thought process is:\u001b[0m\n",
       "\u001b[1;31m- Acknowledge that the code's intent is to scrape realtor data from Buffalo, NY.\u001b[0m\n",
       "\u001b[1;31m- Question why there is an \u001b[0m\u001b[1;31m'error'\u001b[0m\u001b[1;31m key—maybe it's for failed requests elsewhere besides what might be expected.\u001b[0m\n",
       "\u001b[1;31m- Consider possible issues like authentication needed, incorrect pagination handling, and structural HTML problems.\u001b[0m\n",
       "\u001b[1;31m- Suggest adding more robust error handling, logging, and considerations about scraping ethics or遵守.\u001b[0m\n",
       "\u001b[1;31m<\u001b[0m\u001b[1;31m/\u001b[0m\u001b[1;31mthink\u001b[0m\u001b[1;31m>\u001b[0m\n",
       "\n",
       "\u001b[1;31mThe code provided is designed to scrape realtor data from Buffalo, NY, limited to two pages. Here's a concise \u001b[0m\n",
       "\u001b[1;31mexplanation of its functionality and suggested improvements:\u001b[0m\n",
       "\n",
       "\u001b[1;31m### Explanation\u001b[0m\n",
       "\u001b[1;31m1\u001b[0m\u001b[1;31m. **Scraping Process**:\u001b[0m\n",
       "\u001b[1;31m   - Calls `scrape_realtor` with state \u001b[0m\u001b[1;31m\"NY\"\u001b[0m\u001b[1;31m, city \u001b[0m\u001b[1;31m\"buffalo\"\u001b[0m\u001b[1;31m, and \u001b[0m\u001b[1;31m2\u001b[0m\u001b[1;31m pages.\u001b[0m\n",
       "\u001b[1;31m   - Expects the response \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mdata\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m without errors; if an error exists, it exits.\u001b[0m\n",
       "\n",
       "\u001b[1;31m2\u001b[0m\u001b[1;31m. **Data Handling**:\u001b[0m\n",
       "\u001b[1;31m   - The data likely contains various property details such as price, beds, baths, etc., structured in a dictionary\u001b[0m\n",
       "\u001b[1;31mper listing.\u001b[0m\n",
       "\u001b[1;31m   - `save_to_csv` writes this data into a CSV file for further analysis or reporting.\u001b[0m\n",
       "\n",
       "\u001b[1;31m3\u001b[0m\u001b[1;31m. **Potential Issues**:\u001b[0m\n",
       "\u001b[1;31m   - Assumes the response is an empty \u001b[0m\u001b[1;31m'error'\u001b[0m\u001b[1;31m key upon failure, but realtor sites might have different error \u001b[0m\n",
       "\u001b[1;31mindicators.\u001b[0m\n",
       "\u001b[1;31m   - Does not handle authentication issues common on some websites that require login for scraping.\u001b[0m\n",
       "\u001b[1;31m   - Might fail if HTML structure changes between requests due to updates by realtor listings.\u001b[0m\n",
       "\u001b[1;31m   - Could encounter pagination limits without proper handling of JavaScript or APIs.\u001b[0m\n",
       "\n",
       "\u001b[1;31m### Suggestions for Improvement\u001b[0m\n",
       "\u001b[1;31m- **Error Handling**: Expand beyond checking the \u001b[0m\u001b[1;31m'error'\u001b[0m\u001b[1;31m key. Incorporate detailed exception logging.\u001b[0m\n",
       "\u001b[1;31m- **Authentication**: Implement user agent headers and authentication methods required by the website.\u001b[0m\n",
       "\u001b[1;31m- **Testing**: Test with various states, cities, and page numbers to ensure robustness.\u001b[0m\n",
       "\u001b[1;31m- **Logging**: Add comprehensive logs for trouble-shooting issues efficiently.\u001b[0m\n",
       "\n",
       "\u001b[1;31mThe code seems basic but offers a foundation that requires enhancement for reliability and effectiveness.\u001b[0m\n",
       "\u001b[1;31mMake sure to include code with the correct pattern, for instance:\u001b[0m\n",
       "\u001b[1;31mThoughts: Your thoughts\u001b[0m\n",
       "\u001b[1;31mCode:\u001b[0m\n",
       "\u001b[1;31m```py\u001b[0m\n",
       "\u001b[1;31m# Your python code here\u001b[0m\n",
       "\u001b[1;31m```<end_code\u001b[0m\u001b[1;31m>\u001b[0m\n",
       "\u001b[1;31mMake sure to provide correct code blobs.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 562.34 seconds| Input tokens: 89 | Output tokens: 1,145]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 562.34 seconds| Input tokens: 89 | Output tokens: 1,145]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = agent.run(\"\"\"\n",
    "Thought: Let's scrape realtor data\n",
    "Code:\n",
    "```python\n",
    "# Scrape realtor data\n",
    "data = scrape_realtor(state=\"NY\", city_name=\"buffalo\", num_pages=2)\n",
    "\n",
    "# Save to CSV\n",
    "if \"error\" not in data:\n",
    "    result = save_to_csv(data)\n",
    "    print(result)\n",
    "else:\n",
    "    print(f\"Error: {data['error']}\")\n",
    "```\n",
    "\"\"\")\n",
    "    \n",
    "print(result)\n",
    "GradioUI(agent).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
