{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing PDFs...\n",
      "Created 53 chunks from PDFs\n",
      "Creating vector store...\n",
      "Clearing existing vector store at chroma_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\deepseek-r1-experiment-notebooks\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vector store...\n",
      "Vector store created and persisted at chroma_db\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def load_and_process_pdfs(data_dir: str):\n",
    "    \"\"\"Load PDFs from directory and split into chunks.\"\"\"\n",
    "    loader = DirectoryLoader(\n",
    "        data_dir,\n",
    "        glob=\"**/*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks\n",
    "\n",
    "def create_vector_store(chunks, persist_directory: str):\n",
    "    \"\"\"Create and persist Chroma vector store.\"\"\"\n",
    "    # Clear existing vector store if it exists\n",
    "    if os.path.exists(persist_directory):\n",
    "        print(f\"Clearing existing vector store at {persist_directory}\")\n",
    "        shutil.rmtree(persist_directory)\n",
    "    \n",
    "    # Initialize HuggingFace embeddings\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "        model_kwargs={'device': 'cpu'}\n",
    "    )\n",
    "    \n",
    "    # Create and persist Chroma vector store\n",
    "    print(\"Creating new vector store...\")\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    return vectordb\n",
    "\n",
    "def main():\n",
    "    # Define directories\n",
    "    data_dir =\"data\"\n",
    "    db_dir = \"chroma_db\"\n",
    "    \n",
    "    # Process PDFs\n",
    "    print(\"Loading and processing PDFs...\")\n",
    "    chunks = load_and_process_pdfs(data_dir)\n",
    "    print(f\"Created {len(chunks)} chunks from PDFs\")\n",
    "    \n",
    "    # Create vector store\n",
    "    print(\"Creating vector store...\")\n",
    "    vectordb = create_vector_store(chunks, db_dir)\n",
    "    print(f\"Vector store created and persisted at {db_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://51352b61a3968886e9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://51352b61a3968886e9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">hi</span>                                                                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIServerModel - llama3.2 ──────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mhi\u001b[0m                                                                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIServerModel - llama3.2 \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'rag_with_reasoner' with arguments: {'user_query': \"{'type': 'string', 'description': 'The user's │\n",
       "│ question to query the vector database with'}\"}                                                                  │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'rag_with_reasoner' with arguments: {'user_query': \"{'type': 'string', 'description': 'The user's │\n",
       "│ question to query the vector database with'}\"}                                                                  │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Based on the following context, answer the user's question. Be concise and specific.</span>                            <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    If there isn't sufficient information, give as your answer a better query to perform RAG with.</span>              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">    </span>                                                                                                            <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Context:</span>                                                                                                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">multi-word entities are not present (such as New York).</span>                                                         <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">We evaluate the overall accuracy for all question types, and for each question type separately (se-</span>             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">mantic, syntactic). Question is assumed to be correctly answered only if the closest word to the</span>                <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">vector computed using the above method is exactly the same as the correct word in the question;</span>                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">synonyms are thus counted as mistakes. This also means that reaching 100% accuracy is likely</span>                    <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">to be impossible, as the current models do not have any input information about word morphology.</span>                <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">However, we believe that usefulness of the word vectors for certain applications should be positively</span>           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">correlated with this accuracy metric. Further progress can be achieved by incorporating information</span>             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">about structure of words, especially for the syntactic questions.</span>                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">4.2 Maximization of Accuracy</span>                                                                                    <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">We have used a Google News corpus for training the word vectors. This corpus contains about</span>                     <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">be expected that these applications can beneﬁt from the model architectures described in this paper.</span>            <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Our ongoing work shows that the word vectors can be successfully applied to automatic extension</span>                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">of facts in Knowledge Bases, and also for veriﬁcation of correctness of existing facts. Results</span>                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">from machine translation experiments also look very promising. In the future, it would be also</span>                  <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">interesting to compare our techniques to Latent Relational Analysis [30] and others. We believe that</span>            <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">our comprehensive test set will help the research community to improve the existing techniques for</span>              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">estimating the word vectors. We also expect that high quality word vectors will become an important</span>             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">building block for future NLP applications.</span>                                                                     <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">10</span>                                                                                                              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">resulting vectors can be used to answer very subtle semantic relationships between words, such as</span>               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">a city and the country it belongs to, e.g. France is to Paris as Germany is to Berlin. Word vectors</span>             <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">with such semantic relationships could be used to improve many existing NLP applications, such</span>                  <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">as machine translation, information retrieval and question answering systems, and may enable other</span>              <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">future applications yet to be invented.</span>                                                                         <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">5</span>                                                                                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Question: {'type': 'string', 'description': 'The user's question to query the vector database with'}</span>            <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Answer:</span>                                                                                                         <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ OpenAIServerModel - deepseek-r1:7b ────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mBased on the following context, answer the user's question. Be concise and specific.\u001b[0m                            \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    If there isn't sufficient information, give as your answer a better query to perform RAG with.\u001b[0m              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m    \u001b[0m                                                                                                            \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mContext:\u001b[0m                                                                                                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mmulti-word entities are not present (such as New York).\u001b[0m                                                         \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mWe evaluate the overall accuracy for all question types, and for each question type separately (se-\u001b[0m             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mmantic, syntactic). Question is assumed to be correctly answered only if the closest word to the\u001b[0m                \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mvector computed using the above method is exactly the same as the correct word in the question;\u001b[0m                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1msynonyms are thus counted as mistakes. This also means that reaching 100% accuracy is likely\u001b[0m                    \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mto be impossible, as the current models do not have any input information about word morphology.\u001b[0m                \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mHowever, we believe that usefulness of the word vectors for certain applications should be positively\u001b[0m           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mcorrelated with this accuracy metric. Further progress can be achieved by incorporating information\u001b[0m             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mabout structure of words, especially for the syntactic questions.\u001b[0m                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m4.2 Maximization of Accuracy\u001b[0m                                                                                    \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mWe have used a Google News corpus for training the word vectors. This corpus contains about\u001b[0m                     \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mbe expected that these applications can beneﬁt from the model architectures described in this paper.\u001b[0m            \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mOur ongoing work shows that the word vectors can be successfully applied to automatic extension\u001b[0m                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mof facts in Knowledge Bases, and also for veriﬁcation of correctness of existing facts. Results\u001b[0m                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mfrom machine translation experiments also look very promising. In the future, it would be also\u001b[0m                  \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1minteresting to compare our techniques to Latent Relational Analysis [30] and others. We believe that\u001b[0m            \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mour comprehensive test set will help the research community to improve the existing techniques for\u001b[0m              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mestimating the word vectors. We also expect that high quality word vectors will become an important\u001b[0m             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mbuilding block for future NLP applications.\u001b[0m                                                                     \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m10\u001b[0m                                                                                                              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mresulting vectors can be used to answer very subtle semantic relationships between words, such as\u001b[0m               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1ma city and the country it belongs to, e.g. France is to Paris as Germany is to Berlin. Word vectors\u001b[0m             \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mwith such semantic relationships could be used to improve many existing NLP applications, such\u001b[0m                  \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mas machine translation, information retrieval and question answering systems, and may enable other\u001b[0m              \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mfuture applications yet to be invented.\u001b[0m                                                                         \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m5\u001b[0m                                                                                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mQuestion: {'type': 'string', 'description': 'The user's question to query the vector database with'}\u001b[0m            \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mAnswer:\u001b[0m                                                                                                         \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m OpenAIServerModel - deepseek-r1:7b \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in code parsing:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Your code snippet is invalid, because the regex pattern ```(?:py|python)?\\n(.*?)\\n``` was not found in it.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Here is your code snippet:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">&lt;think&gt;</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Okay, so I need to figure out what word vectors are used for based on the given context. The text mentions that </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">these vectors can help answer very subtle semantic relationships between words. For example, it gives a comparison </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">like France is to Paris as Germany is to Berlin. This clearly shows that the vectors capture semantic and sometimes</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">structural relationships between words.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The text also talks about applications such as machine translation, information retrieval systems, and question </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">answering. So these are practical uses where understanding word relationships is crucial.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Additionally, it's noted that incorporating more word structure information, like morphology, could improve </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">accuracy for syntactic questions. So they're aware of the limitations related to words' endings or forms, which </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">suggests that they might be considering ways to enhance the model in the future.</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Putting this all together, I should mention both the semantic relationships and specific applications using these </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">vectors.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">&lt;/think&gt;</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">The word vectors are designed to capture subtle semantic and structural relationships between words. They </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">facilitate advanced NLP tasks by enabling improved machine translation, information retrieval, and question </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">answering systems. Specifically, they help model relationships such as France is to Paris as Germany is to Berlin. </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Incorporating more word structure could further enhance their effectiveness for syntactic questions.</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Make sure to include code with the correct pattern, for instance:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Thoughts: Your thoughts</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Code:</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">```py</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"># Your python code here</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">```&lt;end_code&gt;</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Make sure to provide correct code blobs.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in code parsing:\u001b[0m\n",
       "\u001b[1;31mYour code snippet is invalid, because the regex pattern ```\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m?:py|python\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m?\\\u001b[0m\u001b[1;31mn\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31m.*?\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m\\n``` was not found in it.\u001b[0m\n",
       "\u001b[1;31mHere is your code snippet:\u001b[0m\n",
       "\u001b[1;31m<\u001b[0m\u001b[1;31mthink\u001b[0m\u001b[1;31m>\u001b[0m\n",
       "\u001b[1;31mOkay, so I need to figure out what word vectors are used for based on the given context. The text mentions that \u001b[0m\n",
       "\u001b[1;31mthese vectors can help answer very subtle semantic relationships between words. For example, it gives a comparison \u001b[0m\n",
       "\u001b[1;31mlike France is to Paris as Germany is to Berlin. This clearly shows that the vectors capture semantic and sometimes\u001b[0m\n",
       "\u001b[1;31mstructural relationships between words.\u001b[0m\n",
       "\n",
       "\u001b[1;31mThe text also talks about applications such as machine translation, information retrieval systems, and question \u001b[0m\n",
       "\u001b[1;31manswering. So these are practical uses where understanding word relationships is crucial.\u001b[0m\n",
       "\n",
       "\u001b[1;31mAdditionally, it's noted that incorporating more word structure information, like morphology, could improve \u001b[0m\n",
       "\u001b[1;31maccuracy for syntactic questions. So they're aware of the limitations related to words' endings or forms, which \u001b[0m\n",
       "\u001b[1;31msuggests that they might be considering ways to enhance the model in the future.\u001b[0m\n",
       "\n",
       "\u001b[1;31mPutting this all together, I should mention both the semantic relationships and specific applications using these \u001b[0m\n",
       "\u001b[1;31mvectors.\u001b[0m\n",
       "\u001b[1;31m<\u001b[0m\u001b[1;31m/\u001b[0m\u001b[1;31mthink\u001b[0m\u001b[1;31m>\u001b[0m\n",
       "\n",
       "\u001b[1;31mThe word vectors are designed to capture subtle semantic and structural relationships between words. They \u001b[0m\n",
       "\u001b[1;31mfacilitate advanced NLP tasks by enabling improved machine translation, information retrieval, and question \u001b[0m\n",
       "\u001b[1;31manswering systems. Specifically, they help model relationships such as France is to Paris as Germany is to Berlin. \u001b[0m\n",
       "\u001b[1;31mIncorporating more word structure could further enhance their effectiveness for syntactic questions.\u001b[0m\n",
       "\u001b[1;31mMake sure to include code with the correct pattern, for instance:\u001b[0m\n",
       "\u001b[1;31mThoughts: Your thoughts\u001b[0m\n",
       "\u001b[1;31mCode:\u001b[0m\n",
       "\u001b[1;31m```py\u001b[0m\n",
       "\u001b[1;31m# Your python code here\u001b[0m\n",
       "\u001b[1;31m```<end_code\u001b[0m\u001b[1;31m>\u001b[0m\n",
       "\u001b[1;31mMake sure to provide correct code blobs.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 258.92 seconds| Input tokens: 480 | Output tokens: 246]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 258.92 seconds| Input tokens: 480 | Output tokens: 246]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from smolagents import OpenAIServerModel, CodeAgent, ToolCallingAgent, HfApiModel, tool, GradioUI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "reasoning_model_id = \"deepseek-r1:7b\"\n",
    "\n",
    "def get_model(model_id):\n",
    "        return OpenAIServerModel(\n",
    "            model_id=model_id,\n",
    "            api_base=\"http://localhost:11434/v1\",\n",
    "            api_key=\"ollama\"\n",
    "        )\n",
    "\n",
    "# Create the reasoner for better RAG\n",
    "reasoning_model = get_model(reasoning_model_id)\n",
    "reasoner = CodeAgent(tools=[], model=reasoning_model, add_base_tools=False, max_steps=2)\n",
    "\n",
    "# Initialize vector store and embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "db_dir = \"chroma_db\"\n",
    "vectordb = Chroma(persist_directory=db_dir, embedding_function=embeddings)\n",
    "\n",
    "@tool\n",
    "def rag_with_reasoner(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    This is a RAG tool that takes in a user query and searches for relevant content from the vector database.\n",
    "    The result of the search is given to a reasoning LLM to generate a response, so what you'll get back\n",
    "    from this tool is a short answer to the user's question based on RAG context.\n",
    "\n",
    "    Args:\n",
    "        user_query: The user's question to query the vector database with.\n",
    "    \"\"\"\n",
    "    # Search for relevant documents\n",
    "    docs = vectordb.similarity_search(user_query, k=3)\n",
    "    \n",
    "    # Combine document contents\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    # Create prompt with context\n",
    "    prompt = f\"\"\"Based on the following context, answer the user's question. Be concise and specific.\n",
    "    If there isn't sufficient information, give as your answer a better query to perform RAG with.\n",
    "    \n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {user_query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Get response from reasoning model\n",
    "    response = reasoner.run(prompt, reset=False)\n",
    "    return response\n",
    "\n",
    "# Create the primary agent to direct the conversation\n",
    "tool_model = get_model(\"llama3.2\")\n",
    "primary_agent = ToolCallingAgent(tools=[rag_with_reasoner], model=tool_model, add_base_tools=False, max_steps=3)\n",
    "\n",
    "# Example prompt: Compare and contrast the services offered by RankBoost and Omni Marketing\n",
    "def main():\n",
    "    GradioUI(primary_agent).launch()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
